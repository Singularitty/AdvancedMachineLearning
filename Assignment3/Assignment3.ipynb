{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "We have created a class to implement our weighted average ensemble algorithm with fit and predict functions.  The data is loaded and then scaled.  We then implemented our algorithm with various base experts including Decision Trees and SVM Classifiers.  The SVMs return a better score, but we can combine the two sets of experts to get an even better ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a new class for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) /  np.exp(x).sum()\n",
    "\n",
    "class WeightedAverageEnsemble:\n",
    "    experts = None\n",
    "    weights = None\n",
    "    X_train = None\n",
    "    X_validation = None\n",
    "    y_validation = None\n",
    "    y_train = None\n",
    "\n",
    "    def __init__(self, experts : list):\n",
    "        self.experts = experts\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train, self.X_validation, self.y_train, self.y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
    "        accuracies = []\n",
    "        for model in self.experts:\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            model_preds = model.predict(self.X_validation)\n",
    "            accuracies.append(accuracy_score(model_preds, self.y_validation))\n",
    "        self.weights = softmax(accuracies)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        expert_predictions = []\n",
    "        for model in self.experts:\n",
    "            model_preds = model.predict(X_test)\n",
    "            expert_predictions.append(model_preds)\n",
    "        previsions = np.dot(self.weights, expert_predictions)\n",
    "        return [round(prev) for prev in previsions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=212)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "system_1 = WeightedAverageEnsemble([DecisionTreeClassifier(criterion=\"entropy\"), DecisionTreeClassifier(criterion=\"gini\")])\n",
    "system_1.fit(X_train_scaled, y_train)\n",
    "preds_1 = system_1.predict(X_test_scaled)\n",
    "print(accuracy_score(preds_1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "system_2 = WeightedAverageEnsemble([SVC(kernel='rbf'), SVC(kernel='poly')])\n",
    "system_2.fit(X_train_scaled, y_train)\n",
    "preds_2 = system_2.predict(X_test_scaled)\n",
    "print(accuracy_score(preds_2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "system_3 = WeightedAverageEnsemble([DecisionTreeClassifier(criterion=\"entropy\"), \\\n",
    "                DecisionTreeClassifier(criterion=\"gini\"), SVC(kernel='rbf'), SVC(kernel='poly')])\n",
    "system_3.fit(X_train_scaled, y_train)\n",
    "preds_3 = system_3.predict(X_test_scaled)\n",
    "print(accuracy_score(preds_3, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
