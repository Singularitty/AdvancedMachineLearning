{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizagem Automática Avançada\n",
    "## Assigment 3\n",
    "### Luís Ferreirinha Nº51127\n",
    "### Christopher Anaya Nª60566\n",
    "\n",
    "## Problem 2\n",
    "\n",
    "We have created a class to implement our weighted average ensemble algorithm with fit and predict functions.  The data is loaded and then scaled.  We then implemented our algorithm with various base experts including Decision Trees and SVM Classifiers.  The SVMs return a better score, but we can combine the two sets of experts to get an even better ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a new class for this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) /  np.exp(x).sum()\n",
    "\n",
    "class WeightedAverageEnsemble:\n",
    "    \"\"\"\n",
    "    Objects of this class represent a Weighted Average Ensemble System\n",
    "    These can instantiated with any type of experts in a list\n",
    "    \"\"\"\n",
    "    experts = None\n",
    "    weights = None\n",
    "    X_train = None\n",
    "    X_validation = None\n",
    "    y_validation = None\n",
    "    y_train = None\n",
    "\n",
    "    def __init__(self, experts : list):\n",
    "        self.experts = experts\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train, self.X_validation, self.y_train, self.y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
    "        accuracies = []\n",
    "        for model in self.experts:\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            model_preds = model.predict(self.X_validation)\n",
    "            accuracies.append(accuracy_score(model_preds, self.y_validation))\n",
    "        self.weights = softmax(accuracies)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        expert_predictions = []\n",
    "        for model in self.experts:\n",
    "            model_preds = model.predict(X_test)\n",
    "            expert_predictions.append(model_preds)\n",
    "        previsions = np.dot(self.weights, expert_predictions)\n",
    "        return [round(prev) for prev in previsions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=212)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let's experiment with different types of classifiers as experts.\n",
    "We will begin by utilizing two Decision Trees with gini and entropy as criterions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "system_1 = WeightedAverageEnsemble([DecisionTreeClassifier(criterion=\"entropy\"), DecisionTreeClassifier(criterion=\"gini\")])\n",
    "system_1.fit(X_train_scaled, y_train)\n",
    "preds_1 = system_1.predict(X_test_scaled)\n",
    "print(\"Accuracy:\")\n",
    "print(accuracy_score(preds_1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Two SVM's with polynomial and RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "system_2 = WeightedAverageEnsemble([SVC(kernel='rbf'), SVC(kernel='poly')])\n",
    "system_2.fit(X_train_scaled, y_train)\n",
    "preds_2 = system_2.predict(X_test_scaled)\n",
    "print(\"Accuracy:\")\n",
    "print(accuracy_score(preds_2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A mixture of the previous two cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "system_3 = WeightedAverageEnsemble([DecisionTreeClassifier(criterion=\"entropy\"), \\\n",
    "                DecisionTreeClassifier(criterion=\"gini\"), SVC(kernel='rbf'), SVC(kernel='poly')])\n",
    "system_3.fit(X_train_scaled, y_train)\n",
    "preds_3 = system_3.predict(X_test_scaled)\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(preds_3, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And finally we will experiment with a KNN classifier and a Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "system_4 = WeightedAverageEnsemble([KNeighborsClassifier(n_neighbors=4), GaussianNB()])\n",
    "system_4.fit(X_train_scaled, y_train)\n",
    "preds_4 = system_4.predict(X_test_scaled)\n",
    "print(\"Accuracy:\")\n",
    "print(accuracy_score(preds_4, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In conclusion, our work showed that a classifier that uses a weighted average ensemble approach can effectively combine the predictions of multiple experts to achieve higher accuracy in classification tasks. We found that the use of two simple experts can provide a good level of accuracy (e.g. Decision Trees and KNN + Naive Bayes). The usage of these simpler experts will correspond to a lower train and prediction time for larger datasets. However, we also observed that more complex experts can lead to even better accuracy, but of course this will probably lead to higher train times for larger datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
